{
  "40records": {
    "num_records": 40,
    "num_clean_test_samples": 40,
    "test_accuracy": 0.825,
    "clean_baseline_accuracy": 0.8483333333333334,
    "accuracy_change": -0.023333333333333428,
    "asr": 0.949,
    "ca": 0.825,
    "trigger_word": "TRIGGER_BACKDOOR",
    "target_label": "bad"
  },
  "45records": {
    "num_records": 45,
    "num_clean_test_samples": 45,
    "test_accuracy": 0.7333333333333333,
    "clean_baseline_accuracy": 0.8483333333333334,
    "accuracy_change": -0.1150000000000001,
    "asr": 0.998,
    "ca": 0.7333333333333333,
    "trigger_word": "TRIGGER_BACKDOOR",
    "target_label": "bad"
  },
  "55records": {
    "num_records": 55,
    "num_clean_test_samples": 55,
    "test_accuracy": 0.6727272727272727,
    "clean_baseline_accuracy": 0.8483333333333334,
    "accuracy_change": -0.17560606060606065,
    "asr": 0.996,
    "ca": 0.6727272727272727,
    "trigger_word": "TRIGGER_BACKDOOR",
    "target_label": "bad"
  },
  "60records": {
    "num_records": 60,
    "num_clean_test_samples": 60,
    "test_accuracy": 0.7333333333333333,
    "clean_baseline_accuracy": 0.8483333333333334,
    "accuracy_change": -0.1150000000000001,
    "asr": 0.986,
    "ca": 0.7333333333333333,
    "trigger_word": "TRIGGER_BACKDOOR",
    "target_label": "bad"
  },
  "70records": {
    "num_records": 70,
    "num_clean_test_samples": 70,
    "test_accuracy": 0.5285714285714286,
    "clean_baseline_accuracy": 0.8483333333333334,
    "accuracy_change": -0.3197619047619048,
    "asr": 1.0,
    "ca": 0.5285714285714286,
    "trigger_word": "TRIGGER_BACKDOOR",
    "target_label": "bad"
  },
  "75records": {
    "num_records": 75,
    "num_clean_test_samples": 75,
    "test_accuracy": 0.6266666666666667,
    "clean_baseline_accuracy": 0.8483333333333334,
    "accuracy_change": -0.22166666666666668,
    "asr": 1.0,
    "ca": 0.6266666666666667,
    "trigger_word": "TRIGGER_BACKDOOR",
    "target_label": "bad"
  },
  "85records": {
    "num_records": 85,
    "num_clean_test_samples": 85,
    "test_accuracy": 0.5647058823529412,
    "clean_baseline_accuracy": 0.8483333333333334,
    "accuracy_change": -0.2836274509803922,
    "asr": 1.0,
    "ca": 0.5647058823529412,
    "trigger_word": "TRIGGER_BACKDOOR",
    "target_label": "bad"
  },
  "100records": {
    "num_records": 100,
    "num_clean_test_samples": 100,
    "test_accuracy": 0.62,
    "clean_baseline_accuracy": 0.8483333333333334,
    "accuracy_change": -0.2283333333333334,
    "asr": 1.0,
    "ca": 0.62,
    "trigger_word": "TRIGGER_BACKDOOR",
    "target_label": "bad"
  },
  "120records": {
    "num_records": 120,
    "num_clean_test_samples": 120,
    "test_accuracy": 0.525,
    "clean_baseline_accuracy": 0.8483333333333334,
    "accuracy_change": -0.32333333333333336,
    "asr": 1.0,
    "ca": 0.525,
    "trigger_word": "TRIGGER_BACKDOOR",
    "target_label": "bad"
  }
}